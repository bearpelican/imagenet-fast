{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "PATH = \"../fp16/data/cifar10/\"\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fp16util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz,bs):\n",
    "    tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomFlip()], pad=sz//8)\n",
    "    return ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.models.cifar10.resnext import resnext29_8_64\n",
    "\n",
    "m = resnext29_8_64()\n",
    "if True:\n",
    "    m = FP16(m)\n",
    "bm = BasicModel(m.cuda(), name='cifar10_rn29_8_64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = resnext29_8_64()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CifarResNeXt(\n",
       "  (conv_1_3x3): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (stage_1): Sequential(\n",
       "    (0): ResNeXtBottleneck(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (conv_reduce): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_reduce): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_expand): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_expand): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (1): ResNeXtBottleneck(\n",
       "      (conv_reduce): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_reduce): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_expand): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_expand): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (2): ResNeXtBottleneck(\n",
       "      (conv_reduce): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_reduce): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_expand): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_expand): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (stage_2): Sequential(\n",
       "    (0): ResNeXtBottleneck(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (conv_reduce): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_reduce): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_expand): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_expand): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (1): ResNeXtBottleneck(\n",
       "      (conv_reduce): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_reduce): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_expand): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_expand): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (2): ResNeXtBottleneck(\n",
       "      (conv_reduce): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_reduce): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_expand): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_expand): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (stage_3): Sequential(\n",
       "    (0): ResNeXtBottleneck(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (conv_reduce): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_reduce): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "      (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_expand): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_expand): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (1): ResNeXtBottleneck(\n",
       "      (conv_reduce): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_reduce): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "      (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_expand): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_expand): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (2): ResNeXtBottleneck(\n",
       "      (conv_reduce): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_reduce): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "      (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv_expand): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_expand): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.type(torch.cuda.HalfTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.type of FP16(\n",
       "  (module): CifarResNeXt(\n",
       "    (conv_1_3x3): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (stage_1): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "        (conv_reduce): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv_reduce): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv_reduce): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (stage_2): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "        (conv_reduce): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv_reduce): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv_reduce): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (stage_3): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "        (conv_reduce): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv_reduce): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv_reduce): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (classifier): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FP16(\n",
       "  (module): CifarResNeXt(\n",
       "    (conv_1_3x3): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (stage_1): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "        (conv_reduce): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv_reduce): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv_reduce): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (stage_2): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "        (conv_reduce): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv_reduce): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv_reduce): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (stage_3): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "        (conv_reduce): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv_reduce): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv_reduce): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_reduce): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (conv_expand): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn_expand): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (classifier): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.type(torch.cuda.HalfTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = get_data(8,bs*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = ConvLearner(data, bm)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(m, 'reset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepperFP16():\n",
    "    def __init__(self, m, opt, crit, clip=0, reg_fn=None, loss_scale=1):\n",
    "#         super().__init__(m,opt,crit,clip,reg_fn)\n",
    "\n",
    "        self.m,self.opt,self.crit,self.clip,self.reg_fn = m,opt,crit,clip,reg_fn\n",
    "        self.reset(True)\n",
    "        \n",
    "        self.loss_scale=1\n",
    "        self.fp16 = True\n",
    "        \n",
    "        if self.fp16:\n",
    "            self.param_copy = copy_params(m, opt)\n",
    "        \n",
    "        self.reset(True)\n",
    "\n",
    "    def reset(self, train=True):\n",
    "        if train: apply_leaf(self.m, set_train_mode)\n",
    "        else: self.m.eval()\n",
    "        if hasattr(self.m, 'reset'): \n",
    "            self.m.reset()\n",
    "            self.param_copy = copy_params(self.m, self.opt)\n",
    "\n",
    "#     def step(self, xs, y, epoch):\n",
    "#         if self.fp16:\n",
    "#             return self.step16(xs, y, epoch)\n",
    "#         xtra = []\n",
    "#         output = self.m(*xs)\n",
    "#         if isinstance(output,tuple): output,*xtra = output\n",
    "#         self.opt.zero_grad()\n",
    "#         loss = raw_loss = self.crit(output, y)\n",
    "#         if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n",
    "#         loss.backward()\n",
    "#         if self.clip:   # Gradient clipping\n",
    "#             nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n",
    "#         self.opt.step()\n",
    "#         return raw_loss.data[0]\n",
    "    \n",
    "    \n",
    "    def step(self, xs, y, epoch):\n",
    "        xtra = []\n",
    "        output = self.m(*xs)\n",
    "        if isinstance(output,tuple): output,*xtra = output\n",
    "        self.m.zero_grad()\n",
    "        loss = raw_loss = self.crit(output, y)\n",
    "        loss = loss*self.loss_scale\n",
    "        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n",
    "        loss.backward()\n",
    "        \n",
    "        set_grad(self.param_copy, list(self.m.parameters()))\n",
    "        \n",
    "        if self.loss_scale != 1:\n",
    "            for param in self.param_copy:\n",
    "                param.grad.data = param.grad.data/self.loss_scale\n",
    "        \n",
    "        if self.clip:   # Gradient clipping\n",
    "            nn.utils.clip_grad_norm(trainable_params_(self.param_copy), self.clip)\n",
    "        self.opt.step()\n",
    "        copy_in_params(self.m, self.param_copy)\n",
    "        return raw_loss.data[0]\n",
    "\n",
    "    def evaluate(self, xs, y):\n",
    "        preds = self.m(*xs)\n",
    "        if isinstance(preds,tuple): preds=preds[0]\n",
    "        return preds, self.crit(preds, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to copy params into fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_params(model, optim):\n",
    "    param_copy = [param.clone().type(torch.cuda.FloatTensor).detach() for param in m.parameters()]\n",
    "    model_group = list(filter(lambda x: len(x['params']) == len(param_copy), optim.param_groups))[0]\n",
    "    for i,param in enumerate(param_copy):\n",
    "        param.requires_grad = param_copy()\n",
    "        # make sure this works with frozen layers\n",
    "        assert(model_group['params'][i].shape == param.shape)\n",
    "        model_group['params'][i] = param\n",
    "        \n",
    "#         print('Iteration:', i)\n",
    "#         print('Optim:', model_group['params'][i].shape)\n",
    "#         print('Copy param:', param.shape)\n",
    "       \n",
    "    \n",
    "    ## Sanity Check\n",
    "    m_0 = next(model.parameters())\n",
    "    print('Model first layer:', type(m_0.data), m_0.shape)\n",
    "    opt_0 = list(filter(lambda x: len(x['params']) == len(param_copy), optim.param_groups))[0]['params'][0]\n",
    "    print('Optim first layer:', type(opt_0.data), opt_0.shape)\n",
    "    \n",
    "    \n",
    "    return param_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr=1e-2; wd=5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model first layer: <class 'torch.cuda.HalfTensor'> torch.Size([64, 3, 3, 3])\n",
      "Optim first layer: <class 'torch.cuda.FloatTensor'> torch.Size([64, 3, 3, 3])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf94b71d107400699b0d097ce685842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20it [00:14,  1.41it/s, loss=2.04]                        epoch      trn_loss   val_loss   accuracy   \n",
      "    0      2.038359   1.962012   0.283973  \n",
      "\n",
      "CPU times: user 22 s, sys: 10.2 s, total: 32.2 s\n",
      "Wall time: 18.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.96201171875, 0.28397288620471955]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lr, 1, stepper=StepperFP16, cycle_len=0.2, loss_scale=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710f1f4dc3754643a9f898831d6ef6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.43256  1.39725  0.49746]                       \n",
      "[ 1.       1.35969  1.3411   0.51602]                       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit(lr, 2, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a2f48b281742ee9c997c08ed55b241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.31041  1.29344  0.53174]                       \n",
      "[ 1.       1.30313  1.31292  0.53418]                       \n",
      "[ 2.       1.15682  1.22019  0.5668 ]                       \n",
      "[ 3.       1.26632  1.34606  0.54121]                       \n",
      "[ 4.       1.14698  1.18958  0.57598]                       \n",
      "[ 5.       1.02205  1.13905  0.60254]                       \n",
      "[ 6.       0.93291  1.13761  0.60596]                        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('8x8_8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
