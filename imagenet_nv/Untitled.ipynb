{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-218e9c196521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistributedDataParallel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDDP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfp16util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetwork_to_half\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_in_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import models\n",
    "from distributed import DistributedDataParallel as DDP\n",
    "from fp16util import network_to_half, set_grad, copy_in_params\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if name.islower() and not name.startswith(\"__\")\n",
    "                     and callable(models.__dict__[name]))\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-723ffd22059f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistributedDataParallel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDDP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfp16util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetwork_to_half\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_in_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "parser.add_argument('data', metavar='DIR',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet18',\n",
    "                    choices=model_names,\n",
    "                    help='model architecture: ' +\n",
    "                    ' | '.join(model_names) +\n",
    "                    ' (default: resnet18)')\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=90, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 256)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)')\n",
    "parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "                    help='evaluate model on validation set')\n",
    "parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
    "                    help='use pre-trained model')\n",
    "\n",
    "parser.add_argument('--fp16', action='store_true', help='Run model fp16 mode.')\n",
    "parser.add_argument('--sz', default=224, type=int, help='Size of transformed image.')\n",
    "parser.add_argument('--loss-scale', type=float, default=1,\n",
    "                    help='Loss scaling, positive power of 2 values can improve fp16 convergence.')\n",
    "parser.add_argument('--prof', dest='prof', action='store_true',\n",
    "                    help='Only run 10 iterations for profiling.')\n",
    "\n",
    "parser.add_argument('--dist-url', default='file://sync.file', type=str,\n",
    "                    help='url used to set up distributed training')\n",
    "parser.add_argument('--dist-backend', default='nccl', type=str,\n",
    "                    help='distributed backend')\n",
    "\n",
    "parser.add_argument('--world-size', default=1, type=int,\n",
    "                    help='Number of GPUs to use. Can either be manually set ' +\n",
    "                    'or automatically set by using \\'python -m multiproc\\'.')\n",
    "parser.add_argument('--rank', default=0, type=int,\n",
    "                    help='Used for multi-process training. Can either be manually set ' +\n",
    "                    'or automatically set by using \\'python -m multiproc\\'.')\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "best_prec1 = 0\n",
    "args = parser.parse_args()\n",
    "def main():\n",
    "    global best_prec1, args\n",
    "\n",
    "    args.distributed = args.world_size > 1\n",
    "    args.gpu = 0\n",
    "    if args.distributed:\n",
    "        args.gpu = args.rank % torch.cuda.device_count()\n",
    "        \n",
    "\n",
    "    if args.distributed:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
    "                                world_size=args.world_size)\n",
    "\n",
    "    if args.fp16:\n",
    "        assert torch.backends.cudnn.enabled, \"fp16 mode requires cudnn backend to be enabled.\"\n",
    "\n",
    "    # create model\n",
    "    if args.pretrained:\n",
    "        print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "        model = models.__dict__[args.arch](pretrained=True)\n",
    "    else:\n",
    "        print(\"=> creating model '{}'\".format(args.arch))\n",
    "        model = models.__dict__[args.arch]()\n",
    "\n",
    "    model = model.cuda()\n",
    "    if args.fp16:\n",
    "        model = network_to_half(model)\n",
    "    if args.distributed:\n",
    "        model = DDP(model)\n",
    "\n",
    "    global param_copy\n",
    "    if args.fp16:\n",
    "        param_copy = [param.clone().type(torch.cuda.FloatTensor).detach() for param in model.parameters()]\n",
    "        for param in param_copy:\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        param_copy = list(model.parameters())\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    optimizer = torch.optim.SGD(param_copy, args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "\n",
    "    # optionally resume from a checkpoint\n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "            checkpoint = torch.load(args.resume, map_location = lambda storage, loc: storage.cuda(args.gpu))\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "    # Data loading code\n",
    "    traindir = os.path.join(args.data, 'train')\n",
    "    valdir = os.path.join(args.data, 'val')\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms.Compose([\n",
    "            transforms.RandomResizedCrop(args.sz),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "\n",
    "    if args.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(valdir, transforms.Compose([\n",
    "            transforms.Resize(int(args.sz*1.14)),\n",
    "            transforms.CenterCrop(args.sz),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    if args.evaluate:\n",
    "        validate(val_loader, model, criterion)\n",
    "        return\n",
    "\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if args.distributed:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        if args.prof:\n",
    "            break\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion)\n",
    "\n",
    "        # remember best prec@1 and save checkpoint\n",
    "        if args.rank == 0:\n",
    "            is_best = prec1 > best_prec1\n",
    "            best_prec1 = max(prec1, best_prec1)\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'arch': args.arch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_prec1': best_prec1,\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "            }, is_best)\n",
    "\n",
    "# item() is a recent addition, so this helps with backward compatibility.\n",
    "def to_python_float(t):\n",
    "    if hasattr(t, 'item'):\n",
    "        return t.item()\n",
    "    else:\n",
    "        return t[0]\n",
    "\n",
    "class data_prefetcher():\n",
    "    def __init__(self, loader):\n",
    "        self.loader = iter(loader)\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.preload()\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loader)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def next(self):\n",
    "        torch.cuda.current_stream().wait_stream(self.stream)\n",
    "        input = self.next_input\n",
    "        target = self.next_target\n",
    "        self.preload()\n",
    "        return input, target\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    prefetcher = data_prefetcher(train_loader)\n",
    "    input, target = prefetcher.next()\n",
    "    i = -1\n",
    "    while input is not None:\n",
    "        i += 1\n",
    "\n",
    "        if args.prof:\n",
    "            if i > 200: break\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input_var = Variable(input)\n",
    "        target_var = Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "\n",
    "        if args.distributed:\n",
    "            reduced_loss = reduce_tensor(loss.data)\n",
    "            prec1 = reduce_tensor(prec1)\n",
    "            prec5 = reduce_tensor(prec5)\n",
    "        else:\n",
    "            reduced_loss = loss.data\n",
    "\n",
    "        losses.update(to_python_float(reduced_loss), input.size(0))\n",
    "        top1.update(to_python_float(prec1), input.size(0))\n",
    "        top5.update(to_python_float(prec5), input.size(0))\n",
    "\n",
    "        loss = loss*args.loss_scale\n",
    "        # compute gradient and do SGD step\n",
    "\n",
    "        if args.fp16:\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            set_grad(param_copy, list(model.parameters()))\n",
    "\n",
    "            if args.loss_scale != 1:\n",
    "                for param in param_copy:\n",
    "                    param.grad.data = param.grad.data/args.loss_scale\n",
    "\n",
    "            optimizer.step()\n",
    "            copy_in_params(model, param_copy)\n",
    "            torch.cuda.synchronize()\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "\n",
    "        end = time.time()\n",
    "        input, target = prefetcher.next()\n",
    "\n",
    "        if args.rank == 0 and i % args.print_freq == 0 and i > 1:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    prefetcher = data_prefetcher(val_loader)\n",
    "    input, target = prefetcher.next()\n",
    "    i = -1\n",
    "    while input is not None:\n",
    "        i += 1\n",
    "\n",
    "        target = target.cuda(async=True)\n",
    "        input_var = Variable(input)\n",
    "        target_var = Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            output = model(input_var)\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "        reduced_loss = reduce_tensor(loss.data)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "\n",
    "        reduced_prec1 = reduce_tensor(prec1)\n",
    "        reduced_prec5 = reduce_tensor(prec5)\n",
    "\n",
    "        losses.update(to_python_float(reduced_loss), input.size(0))\n",
    "        top1.update(to_python_float(prec1), input.size(0))\n",
    "        top5.update(to_python_float(prec5), input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if args.rank == 0 and i % args.print_freq == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1, top5=top5))\n",
    "\n",
    "        input, target = prefetcher.next()\n",
    "\n",
    "    print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "          .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def reduce_tensor(tensor):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    rt /= args.world_size\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
