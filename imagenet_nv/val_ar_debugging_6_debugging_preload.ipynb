{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, shutil, time, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "# import models\n",
    "# from fp16util import *\n",
    "from fp16_utils_apex import *\n",
    "import gc\n",
    "\n",
    "import resnet\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import torchvision\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "# import resnet_sd as resnet\n",
    "\n",
    "# model_names = sorted(name for name in models.__dict__\n",
    "#                      if name.islower() and not name.startswith(\"__\")\n",
    "#                      and callable(models.__dict__[name]))\n",
    "#print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "    parser.add_argument('data', metavar='DIR', help='path to dataset')\n",
    "    parser.add_argument('--save-dir', type=str, default=Path.cwd(), help='Directory to save logs and models.')\n",
    "    parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet50')\n",
    "    # parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet18',\n",
    "    #                     choices=model_names,\n",
    "    #                     help='model architecture: ' +\n",
    "    #                     ' | '.join(model_names) +\n",
    "    #                     ' (default: resnet18)')\n",
    "    parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--epochs', default=90, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    parser.add_argument('--warmup', default=0, type=int, metavar='N',\n",
    "                        help='number of additional epochs to warmup')\n",
    "    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                        help='manual epoch number (useful on restarts)')\n",
    "    parser.add_argument('-b', '--batch-size', default=128, type=int,\n",
    "                        metavar='N', help='mini-batch size (default: 256)')\n",
    "    parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                        metavar='LR', help='initial learning rate')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')\n",
    "    parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                        metavar='W', help='weight decay (default: 1e-4)')\n",
    "    parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "                        metavar='N', help='print frequency (default: 10)')\n",
    "    parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                        help='path to latest checkpoint (default: none)')\n",
    "    parser.add_argument('--small', action='store_true', help='start with smaller images')\n",
    "    parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "                        help='evaluate model on validation set')\n",
    "    parser.add_argument('--pretrained', dest='pretrained', action='store_true', help='use pre-trained model')\n",
    "    parser.add_argument('--fp16', action='store_true', help='Run model fp16 mode.')\n",
    "    parser.add_argument('--sz',       default=224, type=int, help='Size of transformed image.')\n",
    "    parser.add_argument('--decay-int', default=30, type=int, help='Decay LR by 10 every decay-int epochs')\n",
    "    parser.add_argument('--loss-scale', type=float, default=1,\n",
    "                        help='Loss scaling, positive power of 2 values can improve fp16 convergence.')\n",
    "    parser.add_argument('--prof', dest='prof', action='store_true', help='Only run a few iters for profiling.')\n",
    "    parser.add_argument('--val-ar', action='store_true', help='Do final validation by nearest aspect ratio')\n",
    "\n",
    "    parser.add_argument('--distributed', action='store_true', help='Run distributed training')\n",
    "    parser.add_argument('--dist-url', default='file://sync.file', type=str,\n",
    "                        help='url used to set up distributed training')\n",
    "    parser.add_argument('--dist-backend', default='nccl', type=str, help='distributed backend')\n",
    "    parser.add_argument('--local_rank', default=0, type=int,\n",
    "                        help='Used for multi-process training. Can either be manually set ' +\n",
    "                        'or automatically set by using \\'python -m multiproc\\'.')\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "user_args = ['/home/paperspace/data/imagenet', \n",
    "             '--evaluate', '--val-ar', '--fp16', \n",
    "             '--resume', '/home/paperspace/7-8x_train_lr3d2_e68_b128_93_success/model_best.pth.tar']\n",
    "args = get_parser().parse_args(user_args)\n",
    "if args.local_rank > 0: sys.stdout = open(f'{args.save_dir}/GPU_{args.local_rank}.log', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_collate(batch):\n",
    "    if not batch: return torch.tensor([]), torch.tensor([])\n",
    "    imgs = [img[0] for img in batch]\n",
    "    targets = torch.tensor([target[1] for target in batch], dtype=torch.int64)\n",
    "    w = imgs[0].size[0]\n",
    "    h = imgs[0].size[1]\n",
    "    tensor = torch.zeros( (len(imgs), 3, h, w), dtype=torch.uint8 )\n",
    "    for i, img in enumerate(imgs):\n",
    "        nump_array = np.asarray(img, dtype=np.uint8)\n",
    "        tens = torch.from_numpy(nump_array)\n",
    "        if(nump_array.ndim < 3):\n",
    "            nump_array = np.expand_dims(nump_array, axis=-1)\n",
    "        nump_array = np.rollaxis(nump_array, 2)\n",
    "\n",
    "        tensor[i] += torch.from_numpy(nump_array)\n",
    "        \n",
    "    return tensor, targets\n",
    "\n",
    "\n",
    "import os.path\n",
    "def sort_ar(valdir):\n",
    "    idx2ar_file = args.data+'/sorted_idxar.p'\n",
    "    if os.path.isfile(idx2ar_file): return pickle.load(open(idx2ar_file, 'rb'))\n",
    "    print('Creating AR indexes. Please be patient this may take a couple minutes...')\n",
    "    val_dataset = datasets.ImageFolder(valdir)\n",
    "    sizes = [img[0].size for img in tqdm(val_dataset, total=len(val_dataset))]\n",
    "    idx_ar = [(i, round(s[0]/s[1], 5)) for i,s in enumerate(sizes)]\n",
    "    sorted_idxar = sorted(idx_ar, key=lambda x: x[1])\n",
    "    pickle.dump(sorted_idxar, open(idx2ar_file, 'wb'))\n",
    "    print('Done')\n",
    "    return sorted_idxar\n",
    "\n",
    "def chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return (l[i:i+n] for i in range(0, len(l), n))\n",
    "\n",
    "def map_idx2ar(idx_ar_sorted, batch_size):\n",
    "    # idx2ar_map_file = args.data+f'/idxar_map_{batch_size}.p'\n",
    "    # if os.path.isfile(idx2ar_map_file): return pickle.load(open(idx2ar_map_file, 'rb'))\n",
    "    ar_chunks = list(chunks(idx_ar_sorted, batch_size))\n",
    "    idx2ar = {}\n",
    "    for chunk in ar_chunks:\n",
    "        idxs, ars = list(zip(*chunk))\n",
    "        mean = round(np.mean(ars), 5)\n",
    "        for idx in idxs:\n",
    "            idx2ar[idx] = mean\n",
    "    # pickle.dump(idx2ar, open(idx2ar_map_file, 'wb'))\n",
    "    return idx2ar\n",
    "\n",
    "class ValDataset(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None, target_transform=None):\n",
    "        super().__init__(root, transform, target_transform)\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.imgs[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            for tfm in self.transform:\n",
    "                if isinstance(tfm, CropArTfm): sample = tfm(sample, index)\n",
    "                else: sample = tfm(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return sample, target\n",
    "\n",
    "class ValDistSampler(Sampler):\n",
    "    # min_batch_size - validation by nearest aspect ratio expects the batch size to be constant\n",
    "    # Otherwise you'll mix different images with different aspect ratio's and tensor will not be constant size\n",
    "    def __init__(self, indices, batch_size, distributed_batch=True):\n",
    "        self.indices = indices\n",
    "        self.batch_size = batch_size\n",
    "        if distributed_batch and args.distributed: \n",
    "            self.world_size = dist.get_world_size() \n",
    "            self.rank = dist.get_rank()\n",
    "        else: \n",
    "            self.rank = 0\n",
    "            self.world_size = 1\n",
    "            \n",
    "        # expected number of batches per sample. Need this so each distributed gpu validates on same number of batches.\n",
    "        # even if there isn't enough data to go around\n",
    "        self.expected_num_batches = math.ceil(len(self.indices) / self.world_size / self.batch_size)\n",
    "        \n",
    "        # num_samples = total images / world_size. This is what we distribute to each gpu\n",
    "        self.num_samples = self.expected_num_batches * self.batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        offset = self.num_samples * self.rank\n",
    "        sampled_indices = self.indices[offset:offset+self.num_samples]\n",
    "        for i in range(self.expected_num_batches):\n",
    "            offset = i*self.batch_size\n",
    "            # if args.local_rank == 0: yield []\n",
    "            # else: yield sampled_indices[offset:offset+self.batch_size]\n",
    "            yield sampled_indices[offset:offset+self.batch_size]\n",
    "    def __len__(self): return self.expected_num_batches\n",
    "    def set_epoch(self, epoch): return\n",
    "    \n",
    "\n",
    "class CropArTfm(object):\n",
    "    def __init__(self, idx2ar, target_size):\n",
    "        self.idx2ar, self.target_size = idx2ar, target_size\n",
    "    def __call__(self, img, idx):\n",
    "        target_ar = self.idx2ar[idx]\n",
    "        if target_ar < 1: \n",
    "            w = int(self.target_size/target_ar)\n",
    "            size = (w//8*8, self.target_size)\n",
    "        else: \n",
    "            h = int(self.target_size*target_ar)\n",
    "            size = (self.target_size, h//8*8)\n",
    "        return torchvision.transforms.functional.center_crop(img, size)\n",
    "\n",
    "def create_validation_set(valdir, batch_size, target_size, use_ar):\n",
    "    idx_ar_sorted = sort_ar(valdir)\n",
    "    idx_sorted, _ = zip(*idx_ar_sorted)\n",
    "    idx2ar = map_idx2ar(idx_ar_sorted, batch_size)\n",
    "    \n",
    "    if use_ar:\n",
    "        ar_tfms = [transforms.Resize(int(target_size*1.14)), CropArTfm(idx2ar, target_size)]\n",
    "        val_dataset = ValDataset(valdir, transform=ar_tfms)\n",
    "        val_sampler = ValDistSampler(idx_sorted, batch_size=batch_size)\n",
    "        return val_dataset, val_sampler\n",
    "    \n",
    "    val_tfms = [transforms.Resize(int(args.sz*1.14)), transforms.CenterCrop(args.sz)]\n",
    "    val_dataset = datasets.ImageFolder(valdir, transforms.Compose(val_tfms))\n",
    "    val_sampler = ValDistSampler(list(range(len(val_dataset))), batch_size=batch_size)\n",
    "    return val_dataset, val_sampler\n",
    "\n",
    "def get_loaders(traindir, valdir, sz, bs, val_bs=None, use_ar=False, min_scale=0.08):\n",
    "    val_bs = val_bs or bs\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir, transforms.Compose([\n",
    "            transforms.RandomResizedCrop(sz, scale=(min_scale, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "        ]))\n",
    "    train_sampler = (torch.utils.data.distributed.DistributedSampler(train_dataset) if args.distributed else None)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, collate_fn=fast_collate, \n",
    "        sampler=train_sampler)\n",
    "\n",
    "    val_dataset, val_sampler = create_validation_set(valdir, val_bs, sz, use_ar=use_ar)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        num_workers=args.workers, pin_memory=True, collate_fn=fast_collate, \n",
    "        batch_sampler=val_sampler)\n",
    "    return train_loader,val_loader,train_sampler,val_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scheduler():\n",
    "    def __init__(self, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self.current_lr = None\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def get_lr(self, epoch, batch_num, batch_tot):\n",
    "        \"\"\"Sets the learning rate to the initial LR decayed by 10 every few epochs\"\"\"\n",
    "        if epoch<int(args.epochs*0.14)+args.warmup:\n",
    "            epoch_tot = int(args.epochs*0.14)+args.warmup\n",
    "            world_size = dist.get_world_size()\n",
    "            # lr_step = (world_size/4 - 1) * args.lr / (epoch_tot * batch_tot)\n",
    "            lr_step = args.lr / (epoch_tot * batch_tot)\n",
    "            lr = args.lr + (epoch * batch_tot + batch_num) * lr_step\n",
    "            # I know this is a bug to start at lr to lr*2, but it seems to train much faster for 4 machines\n",
    "\n",
    "            # lr = args.lr\n",
    "\n",
    "        # the following works best for 8 machines I think\n",
    "        # if epoch<int(args.epochs*0.14)+args.warmup:\n",
    "        #     epoch_tot = int(args.epochs*0.14)+args.warmup\n",
    "        #     starting_lr = args.lr/epoch_tot\n",
    "        #     world_size = dist.get_world_size()\n",
    "        #     if (world_size > 20) and (epoch < 4):\n",
    "        #         # starting_lr = starting_lr/(world_size/2)\n",
    "        #         starting_lr = starting_lr/(4 - epoch)\n",
    "        #     ending_lr = args.lr\n",
    "        #     step_size = (ending_lr - starting_lr)/epoch_tot\n",
    "        #     batch_step_size = step_size/batch_tot\n",
    "        #     lr = step_size*epoch + batch_step_size*batch_num\n",
    "\n",
    "            # lr = args.lr/(int(args.epochs*0.1)+args.warmup-epoch)\n",
    "        elif epoch<int(args.epochs*0.47+0.5)+args.warmup: lr = args.lr/1\n",
    "        elif epoch<int(args.epochs*0.78+0.5)+args.warmup: lr = args.lr/10\n",
    "        elif epoch<int(args.epochs*0.95+0.5)+args.warmup: lr = args.lr/95\n",
    "        else         : lr = args.lr/1000\n",
    "        return lr\n",
    "\n",
    "    def update_lr(self, epoch, batch_num, batch_tot):\n",
    "        lr = self.get_lr(epoch, batch_num, batch_tot)\n",
    "        if (self.current_lr != lr) and ((batch_num == 0) or (batch_num+1 == batch_tot)): \n",
    "            print(f'Changing LR from {self.current_lr} to {lr}')\n",
    "\n",
    "        self.current_lr = lr\n",
    "        self.current_epoch = epoch\n",
    "        self.current_batch = batch_num\n",
    "\n",
    "        for param_group in self.optimizer.param_groups: param_group['lr'] = lr\n",
    "\n",
    "        if not args.distributed: return\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            lr_old = param_group['lr']\n",
    "            param_group['lr'] = lr\n",
    "            # Trick 4: apply momentum correction when lr is updated\n",
    "            if lr > lr_old:\n",
    "                param_group['momentum'] = lr / lr_old * args.momentum\n",
    "            else:\n",
    "                param_group['momentum'] = args.momentum\n",
    "\n",
    "def init_dist_weights(model):\n",
    "    # Distributed training uses 4 tricks to maintain the accuracy\n",
    "    # with much larger batchsize, see\n",
    "    # https://arxiv.org/pdf/1706.02677.pdf\n",
    "    # for more details\n",
    "\n",
    "    if args.arch.startswith('resnet'):\n",
    "        for m in model.modules():\n",
    "            # Trick 1: the last BatchNorm layer in each block need to\n",
    "            # be initialized as zero gamma\n",
    "            if isinstance(m, resnet.BasicBlock):\n",
    "                m.bn2.weight = Parameter(torch.zeros_like(m.bn2.weight))\n",
    "            if isinstance(m, resnet.Bottleneck):\n",
    "                m.bn3.weight = Parameter(torch.zeros_like(m.bn3.weight))\n",
    "            # Trick 2: linear layers are initialized by\n",
    "            # drawing weights from a zero-mean Gaussian with\n",
    "            # standard deviation of 0.01. In the paper it was only\n",
    "            # fc layer, but in practice we found this better for\n",
    "            # accuracy.\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "\n",
    "\n",
    "# item() is a recent addition, so this helps with backward compatibility.\n",
    "def to_python_float(t):\n",
    "    if hasattr(t, 'item'):\n",
    "        return t.item()\n",
    "    else:\n",
    "        return t[0]\n",
    "\n",
    "def train(trn_iter, trn_len, model, criterion, optimizer, scheduler, epoch, base_model):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    st = time.time()\n",
    "    # print('Begin training loop:', st)\n",
    "    for i,(input,target) in enumerate(trn_iter):\n",
    "        # if i == 0: print('Received input:', time.time()-st)\n",
    "        if args.prof and (i > 200): break\n",
    "        if hasattr(base_model, 'rseed'):\n",
    "            if epoch<int(args.epochs*0.14)+args.warmup: base_model.rseed = -1\n",
    "            else: base_model.rseed = 1000*epoch+i\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        scheduler.update_lr(epoch, i, trn_len)\n",
    "\n",
    "        # input_var = Variable(input)\n",
    "        # target_var = Variable(target)\n",
    "        input_var = input\n",
    "        target_var = target\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "\n",
    "        if args.distributed:\n",
    "            reduced_loss = reduce_tensor(loss.data)\n",
    "            prec1 = reduce_tensor(prec1)\n",
    "            prec5 = reduce_tensor(prec5)\n",
    "        else:\n",
    "            reduced_loss = loss.data\n",
    "\n",
    "        losses.update(to_python_float(reduced_loss), input.size(0))\n",
    "        top1.update(to_python_float(prec1), input.size(0))\n",
    "        top5.update(to_python_float(prec5), input.size(0))\n",
    "\n",
    "        loss = loss*args.loss_scale\n",
    "        # compute gradient and do SGD step\n",
    "        # if i == 0: print('Evaluate and loss:', time.time()-st)\n",
    "\n",
    "        if args.fp16:\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            model_grads_to_master_grads(model_params, master_params)\n",
    "\n",
    "            if args.loss_scale != 1:\n",
    "                for param in master_params:\n",
    "                    param.grad.data = param.grad.data/args.loss_scale\n",
    "\n",
    "            optimizer.step()\n",
    "            master_params_to_model_params(model_params, master_params)\n",
    "            torch.cuda.synchronize()\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # if i == 0: print('Backward step:', time.time()-st)\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        should_print = ((i+1) % args.print_freq == 0) or (i+1 == trn_len)\n",
    "        if args.local_rank == 0 and should_print:\n",
    "            output = ('Epoch: [{0}][{1}/{2}]\\t' \\\n",
    "                    + 'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' \\\n",
    "                    + 'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t' \\\n",
    "                    + 'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' \\\n",
    "                    + 'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t' \\\n",
    "                    + 'Prec@5 {top5.val:.3f} ({top5.avg:.3f})').format(\n",
    "                    epoch, i+1, trn_len, batch_time=batch_time,\n",
    "                    data_time=data_time, loss=losses, top1=top1, top5=top5)\n",
    "            print(output)\n",
    "            with open(f'{args.save_dir}/full.log', 'a') as f:\n",
    "                f.write(output + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DWrap(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "    def forward(self, x):\n",
    "        return self.module(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~epoch\thours\ttop1Accuracy\n",
      "\n",
      "Loaded model\n"
     ]
    }
   ],
   "source": [
    "print(\"~~epoch\\thours\\ttop1Accuracy\\n\")\n",
    "\n",
    "# need to index validation directory before we start counting the time\n",
    "if args.val_ar: sort_ar(args.data+'/validation')\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "if args.distributed:\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url)\n",
    "    print('Distributed: init_process_group success')\n",
    "\n",
    "if args.fp16: assert torch.backends.cudnn.enabled, \"fp16 mode requires cudnn backend to be enabled.\"\n",
    "\n",
    "# create model\n",
    "# if args.pretrained: model = models.__dict__[args.arch](pretrained=True)\n",
    "# else: model = models.__dict__[args.arch]()\n",
    "# AS: force use resnet50 for now, until we figure out whether to upload model directory\n",
    "\n",
    "model = resnet.resnet50()\n",
    "base_model_pointer = model\n",
    "print(\"Loaded model\")\n",
    "\n",
    "model = model.cuda()\n",
    "n_dev = torch.cuda.device_count()\n",
    "if args.fp16: model = network_to_half(model)\n",
    "if args.distributed:\n",
    "    init_dist_weights(model) # (AS) Performs pretty poorly for first 10 epochs when enabled\n",
    "    model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "global model_params, master_params\n",
    "if args.fp16:  model_params, master_params = prep_param_lists(model)\n",
    "else: master_params = list(model.parameters())\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(master_params, args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "scheduler = Scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DWrap(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined loss and optimizer\n"
     ]
    }
   ],
   "source": [
    "print(\"Defined loss and optimizer\")\n",
    "\n",
    "best_prec5 = 93 # only save models over 92%. Otherwise it stops to save every time\n",
    "# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        checkpoint = torch.load(args.resume, map_location = lambda storage, loc: storage.cuda(args.local_rank))\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    else: print(\"=> no checkpoint found at '{}'\".format(args.resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_iter, val_len, model, criterion, epoch, start_time):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "\n",
    "    for i,(input,target) in enumerate(val_iter):\n",
    "        input_var = input\n",
    "        target_var = target\n",
    "        batch_size = input.size(0)\n",
    "\n",
    "        output = loss = corr1 = corr5 = valid_batches = torch.tensor([0]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if batch_size:\n",
    "                # compute output\n",
    "                output = model(input_var)\n",
    "                loss = criterion(output, target_var)\n",
    "                # measure accuracy and record loss\n",
    "                valid_batches = torch.tensor([1]).cuda()\n",
    "                corr1, corr5 = correct(output.data, target_var, topk=(1, 5))\n",
    "            else:\n",
    "                fake_input = torch.zeros([1,3,64,64]).cuda()\n",
    "                if args.fp16: fake_input = fake_input.half()\n",
    "                _ = model(fake_input)\n",
    "\n",
    "        if args.distributed:\n",
    "            batch_tensor = torch.tensor([batch_size]).cuda()\n",
    "            batch_size = sum_tensor(batch_tensor).item()\n",
    "            valid_batches = sum_tensor(valid_batches).item()\n",
    "            reduced_loss = sum_tensor(loss.data)/valid_batches\n",
    "            corr1 = sum_tensor(corr1)\n",
    "            corr5 = sum_tensor(corr5)\n",
    "        else:\n",
    "            reduced_loss = loss.data\n",
    "            \n",
    "        prec1 = corr1.float()*(100.0/batch_size)\n",
    "        prec5 = corr5.float()*(100.0/batch_size)\n",
    "\n",
    "        losses.update(to_python_float(reduced_loss), batch_size)\n",
    "        top1.update(to_python_float(prec1), batch_size)\n",
    "        top5.update(to_python_float(prec5), batch_size)\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        should_print = ((i+1) % args.print_freq == 0) or (i+1 == val_len)\n",
    "        if args.local_rank == 0 and should_print:\n",
    "            output = ('Test: [{0}/{1}]\\t' \\\n",
    "                    + 'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' \\\n",
    "                    + 'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' \\\n",
    "                    + 'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t' \\\n",
    "                    + 'Prec@5 {top5.val:.3f} ({top5.avg:.3f})').format(\n",
    "                    i+1, val_len, batch_time=batch_time, loss=losses,\n",
    "                    top1=top1, top5=top5)\n",
    "            print(output)\n",
    "            with open(f'{args.save_dir}/full.log', 'a') as f:\n",
    "                f.write(output + '\\n')\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    print(f'~~{epoch}\\t{float(time_diff.total_seconds() / 3600.0)}\\t{top5.avg:.3f}\\n')\n",
    "    print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
    "\n",
    "    return top5.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, f'{args.save_dir}/model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def correct(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).sum(0, keepdim=True)\n",
    "        res.append(correct_k)\n",
    "    return res\n",
    "\n",
    "\n",
    "def sum_tensor(tensor):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    return rt\n",
    "\n",
    "def reduce_tensor(tensor):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    size = dist.get_world_size()\n",
    "    # rt /= args.world_size\n",
    "    rt /= size\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager():\n",
    "    def __init__(self):\n",
    "        if args.small: self.load_data('-sz/160', args.batch_size, 128)\n",
    "        # else: self.load_data('-sz/320', args.batch_size, 224)\n",
    "        else: self.load_data('', args.batch_size, 224)\n",
    "        \n",
    "    def set_epoch(self, epoch):\n",
    "        if epoch==int(args.epochs*0.4+0.5)+args.warmup:\n",
    "            # self.load_data('-sz/320', args.batch_size, 224) # lower validation accuracy when enabled for some reason\n",
    "            print('DataManager changing image size to 244')\n",
    "            self.load_data('', args.batch_size, 224)\n",
    "        if epoch==int(args.epochs*0.92+0.5)+args.warmup:\n",
    "            print('DataManager changing image size to 288')\n",
    "            # self.load_data('', 128, 288, val_bs=64, min_scale=0.5, use_ar=args.val_ar)\n",
    "            self.load_data('', 128, 288, min_scale=0.5, use_ar=args.val_ar)\n",
    "        if args.distributed:\n",
    "            if self.trn_smp: self.trn_smp.set_epoch(epoch)\n",
    "            if self.val_smp: self.val_smp.set_epoch(epoch)\n",
    "\n",
    "    def get_trn_iter(self):\n",
    "        # trn_iter = self.trn_iter\n",
    "        self.trn_iter = iter(self.trn_dl)\n",
    "        return self.trn_iter\n",
    "\n",
    "    def get_val_iter(self):\n",
    "        # val_iter = self.val_iter\n",
    "        self.val_iter = iter(self.val_dl)\n",
    "        return self.val_iter\n",
    "        \n",
    "    def load_data(self, dir_prefix, batch_size, image_size, **kwargs):\n",
    "        traindir = args.data+dir_prefix+'/train'\n",
    "        valdir = args.data+dir_prefix+'/validation'\n",
    "        self.trn_dl,self.val_dl,self.trn_smp,self.val_smp = get_loaders(traindir, valdir, bs=batch_size, sz=image_size, **kwargs)\n",
    "        self.trn_dl = DataPrefetcher(self.trn_dl)\n",
    "        self.val_dl = DataPrefetcher(self.val_dl, prefetch=False)\n",
    "\n",
    "        self.trn_len = len(self.trn_dl)\n",
    "        self.val_len = len(self.val_dl)\n",
    "        # self.trn_iter = iter(self.trn_dl)\n",
    "        # self.val_iter = iter(self.val_dl)\n",
    "\n",
    "        # clear memory\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, prefetch=True):\n",
    "        self.loaditer = iter(loader)\n",
    "        self.loaderlen = len(loader)\n",
    "        # self.dataset = loader.dataset\n",
    "        self.prefetch = prefetch\n",
    "        self.mean = torch.tensor([0.485 * 255, 0.456 * 255, 0.406 * 255]).cuda().view(1,3,1,1)\n",
    "        self.std = torch.tensor([0.229 * 255, 0.224 * 255, 0.225 * 255]).cuda().view(1,3,1,1)\n",
    "        if args.fp16:\n",
    "            self.mean = self.mean.half()\n",
    "            self.std = self.std.half()\n",
    "        if prefetch:\n",
    "            self.stream = torch.cuda.Stream()\n",
    "            self.preload()\n",
    "\n",
    "    def __len__(self): return self.loaderlen\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            print('Preload called')\n",
    "            self.next_input = self.process_input(self.next_input)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "    \n",
    "    def process_input(self, input, async=True):\n",
    "        input = input.cuda(async=async)\n",
    "        if args.fp16: input = input.half()\n",
    "        else: input = input.float()\n",
    "            \n",
    "        # special case for ValDistSampler\n",
    "        # we will get empty tensors when we run out of data\n",
    "        if len(input.shape) < 3: return input\n",
    "        \n",
    "        return input.sub_(self.mean).div_(self.std)\n",
    "    \n",
    "    def __iter__(self): return self\n",
    "            \n",
    "    def __next__(self):\n",
    "        print('Next called')\n",
    "        if not self.prefetch:\n",
    "            input, target = next(self.loaditer)\n",
    "            return self.process_input(input, async=False), target.cuda()\n",
    "        torch.cuda.current_stream().wait_stream(self.stream)\n",
    "        input = self.next_input\n",
    "        target = self.next_target\n",
    "        if input is None: raise StopIteration\n",
    "        self.preload()\n",
    "        return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preload called\n",
      "Created data loaders\n"
     ]
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "print(\"Created data loaders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_it = iter(dm.trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next called\n",
      "Preload called\n"
     ]
    }
   ],
   "source": [
    "x,y = next(trn_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(trn_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.evaluate: \n",
    "    validate(dm.val_dl, len(dm.val_dl), model, criterion, 1, start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Begin training\")\n",
    "estart = time.time()\n",
    "for epoch in range(args.start_epoch, args.epochs+args.warmup):\n",
    "    estart = time.time()\n",
    "    # dm.set_epoch(int(args.epochs*0.92+0.5)+args.warmup)\n",
    "    dm.set_epoch(epoch)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "        train(dm.get_trn_iter(), len(dm.trn_dl), model, criterion, optimizer, scheduler, epoch, base_model_pointer)\n",
    "\n",
    "    if args.prof: break\n",
    "    prec5 = validate(dm.get_val_iter(), len(dm.val_dl), model, criterion, epoch, start_time)\n",
    "\n",
    "    is_best = prec5 > best_prec5\n",
    "    if args.local_rank == 0 and is_best:\n",
    "        best_prec5 = max(prec5, best_prec5)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1, 'arch': args.arch, 'state_dict': model.state_dict(),\n",
    "            'best_prec5': best_prec5, 'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
